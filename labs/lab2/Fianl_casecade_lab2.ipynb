{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fianl casecade lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mirab62807/DataScience/blob/main/labs/lab2/Fianl_casecade_lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCi_99yMYIb1"
      },
      "source": [
        "In this notebook you'll create your own bootstrap function following the bootstrap algorithm (check the lecture notes!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY5zujI2YC37",
        "pycharm": {
          "name": "#%%# Imports\n"
        }
      },
      "source": [
        "import matplotlib\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqkwj4SMY38t",
        "outputId": "07328c4b-1c0d-4e2e-cb26-56672a57656b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/albanda/CE888/master/lab2%20-%20bootstrap/customers.csv')\n",
        "data = df.values.T[1]\n",
        "print(data.shape[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxvc_bScYC4H",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Checking the notes from the lecture, create here your own bootstrap function:\n",
        "# 1. Sample from the input array x to create an array of samples of shape (n_bootstraps, sample_size)\n",
        "# Hint: Check the function random.choice() on Numpy\n",
        "# 2. Calculate and save the mean of the array (this is \"data_mean\" that is returned by the function)\n",
        "# 3. Calculate the mean from each bootstrap (i.e., row) and store it.\n",
        "# (This should be an array of n_bootstraps values)\n",
        "# 4. Calculate the lower and upper bounds for a 95% CI (hint: check the percentile function on Numpy)\n",
        "# 5. Return data_mean, and the lower and upper bounds of your interval\n",
        "def bootstrap_mean(x, sample_size, n_bootstraps):\n",
        "\tbootstrap_matrix = []\n",
        "\tfor i in range(n_bootstraps):\n",
        "\t\tboot_str = np.random.choice(data, sample_size)     #p=[1/sample_size]*sample_size)\n",
        "\t\tbootstrap_matrix.append(boot_str)\n",
        "        \n",
        "\tbootstrap_array = np.array(bootstrap_matrix)\n",
        "\t#print(bootstrap_array)\n",
        "\tdata_mean = np.mean(bootstrap_array, axis = 1)\n",
        "\t#print(data_mean)\n",
        "\tlower = np.percentile(data_mean, 2.5)\n",
        "\tupper = np.percentile(data_mean, 97.5)\n",
        "\treturn data_mean, lower, upper\n",
        "\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN7sEOcMYC4P",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Call your bootstrap function and plot the results\n",
        "\n",
        "boots = []\n",
        "for i in range(100, 50000, 1000):\n",
        "    boot = bootstrap_mean(data, data.shape[0], i)\n",
        "    boots.append([i, boot[0], \"mean\"])\n",
        "    boots.append([i, boot[1], \"lower\"])\n",
        "    boots.append([i, boot[2], \"upper\"])\n",
        "\n",
        "\n",
        "print(boots)\n",
        "\n",
        "df_boot = pd.DataFrame(boots, columns=['Bootstrap Iterations', 'Mean', \"Value\"])\n",
        "print(df_boot)\n",
        "#print(df_boot.values.T[0])\n",
        "#print(df_boot.values.T[1])\n",
        "#sns_plot = sns.lmplot(df_boot.columns[0], df_boot.columns[1],data=df_boot )\n",
        "\n",
        "#sns_plot.axes[0, 0].set_ylim(0,)\n",
        "#sns_plot.axes[0, 0].set_xlim(0, 50000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjtP4e2_YC4V"
      },
      "source": [
        "\n",
        "Now, modify the bootstrap function you created above so that you can pass your desired confidence interval as a parameter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K9j0FuGYhHs"
      },
      "source": [
        "def bootstrap_mean_ci(data_from_file, data_size, n_bootstraps, ci):\n",
        "  bootstrap_matrix = []\n",
        "  take_arr = []\n",
        "  for i in data_from_file:\n",
        "    if math.isnan(i) == False:\n",
        "      take_arr.append(i)\n",
        "\n",
        "  size_no_nan = len(take_arr)\n",
        "  no_nan_array = np.array(take_arr)\n",
        "  for i in range (n_bootstraps):\n",
        "    boot_str = np.random.choice(no_nan_array,size_no_nan)\n",
        "    bootstrap_matrix.append(boot_str)\n",
        "\n",
        "  bootstrap_array = np.array(bootstrap_matrix)\n",
        "  \n",
        "  data_mean = np.mean(bootstrap_array, axis = 1)\n",
        "  #data_mean_withpercentile = np.percentile(data_mean, ci)\n",
        "  #print('with {} confidence interval mean is {}'.format(ci, data_mean_withpercentile))\n",
        "  a = 100 - ci \n",
        "  b = a/2\n",
        "\n",
        "  lower = np.percentile(data_mean, b)\n",
        "  print(lower)\n",
        "  upper = np.percentile(data_mean,ci+b)\n",
        "  print(upper)\n",
        "  means_bootstraps_with_ci = upper-lower\n",
        "  return means_bootstraps_with_ci\n",
        "\n",
        "\n",
        "#q2 = bootstrap_mean_ci(data2, len(data2), 10000, 95)\n",
        "#print(q2)\n",
        "\n",
        "# this is for std of CI \n",
        "def bootstrap_std_mean_ci(data_from_file, data_size, n_bootstraps, ci):\n",
        "  bootstrap_matrix = []\n",
        "  take_arr = []\n",
        "  for i in data_from_file:\n",
        "    if math.isnan(i) == False:\n",
        "      take_arr.append(i)\n",
        "\n",
        "  size_no_nan = len(take_arr)\n",
        "  no_nan_array = np.array(take_arr)\n",
        "  for i in range (n_bootstraps):\n",
        "    boot_str = np.random.choice(no_nan_array,size_no_nan)\n",
        "    bootstrap_matrix.append(boot_str)\n",
        "\n",
        "  bootstrap_array = np.array(bootstrap_matrix)\n",
        "  \n",
        "  data_std = np.std(bootstrap_array, axis = 1)\n",
        "  #data_mean_withpercentile = np.percentile(data_mean, ci)\n",
        "  #print('with {} confidence interval mean is {}'.format(ci, data_mean_withpercentile))\n",
        "  a = 100 - ci \n",
        "  b = a/2\n",
        "\n",
        "  lower = np.percentile(data_std, b)\n",
        "  print(lower)\n",
        "  upper = np.percentile(data_std,ci+b)\n",
        "  print(upper)\n",
        "  means_bootstraps_with_std_ci = upper-lower\n",
        "  return means_bootstraps_with_std_ci\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDnjq08GYl-C"
      },
      "source": [
        "boots = []\n",
        "for i in range(100, 50000, 1000):\n",
        "    boot = bootstrap_mean_ci(data1, data1.shape[0], i, 80)\n",
        "    boots.append([i, boot[0], \"mean\"])\n",
        "    boots.append([i, boot[1], \"lower\"])\n",
        "    boots.append([i, boot[2], \"upper\"])\n",
        "\n",
        "df_boot = pd.DataFrame(boots, columns=['Boostrap Iterations', 'Mean', \"Value\"])\n",
        "sns_plot = sns.lmplot(df_boot.columns[0], df_boot.columns[1], data=df_boot, fit_reg=False, hue=\"Value\")\n",
        "\n",
        "sns_plot.axes[0, 0].set_ylim(0,)\n",
        "sns_plot.axes[0, 0].set_xlim(0, 50000)\n",
        "\n",
        "sns_plot.savefig(\"bootstrap_confidence_80.pdf\", bbox_inches='tight')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjNgXW6wdd7r"
      },
      "source": [
        "# Vehicles dataset\n",
        "\n",
        "Now let's work on a different dataset, which is stored in the vehicles.csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avWv4ipFdpka"
      },
      "source": [
        "from IPython.core.pylabtools import figsize\n",
        "# Load and visualise the vehicles dataset\n",
        "# To load the dataset: https://neptune.ai/blog/google-colab-dealing-with-files (check section \"Load individual files directly from GitHub\")\n",
        "\n",
        "\n",
        "# Note that the current and new fleets are in different columns and have different lengths, so bear this in mind when you're plotting.\n",
        "# You can create separate scatterplots for the two fleets, as you would with the histograms, \n",
        "# or plot them both in one plot (but not one against the other).\n",
        "# <---INSERT YOUR CODE HERE--->\n",
        "# Note: you can add more cells as needed to organise your code and your plots\n",
        "\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/albanda/CE888/master/lab2%20-%20bootstrap/vehicles.csv')\n",
        "print(df.columns)\n",
        "data1 = df['Current fleet'].values\n",
        "#print(data1)\n",
        "data2 = df['New Fleet'].values\n",
        "#print(data2)\n",
        "print(len(data2))\n",
        "id = np.arange(1,len(df)+1)\n",
        "df['id'] = id\n",
        "print(len(df))\n",
        "#print(df.head())\n",
        "#sns.scatterplot(data=df, x=\"id\", y=\"Current fleet\")\n",
        "#sns.scatterplot(data=df, x=\"id\", y=\"New Fleet\")\n",
        "\n",
        "# shading because data1,data2 want to use but dont draw graph\n",
        "\n",
        "fig, ayes = plt.subplots(1,2, figsize=(15, 5), sharex=True)\n",
        "fig.suptitle('Scatter Plot')\n",
        "sns.scatterplot(ax=ayes[0], data=df, x=\"id\", y=\"Current fleet\")\n",
        "sns.scatterplot(ax=ayes[1], data=df, x=\"id\", y=\"New Fleet\")\n",
        "\n",
        "sns.displot(data=df.values.T[0], rug=False)\n",
        "plt.xlabel(\"current fleet\")\n",
        "plt.ylabel(\"count\")\n",
        "\n",
        "sns.displot(data=df.values.T[1], rug=False)\n",
        "plt.xlabel(\"New fleet\")\n",
        "plt.ylabel(\"count\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5d0tXDpIEj8"
      },
      "source": [
        "## Compare the two fleets\n",
        "\n",
        "The business analysts come up a comparison algorithm that requires the upper and lower bounds for the mean in order to say which fleet is better.\n",
        "1. Calculate the mean of both samples.\n",
        "2. Using the bootstrap function that you created:\n",
        "    - Construct the 95% CI of the mean of the current fleet.\n",
        "    - Construct the 95% CI of the mean of the new fleet.\n",
        "    - Are they comparable? (i.e., is one better than the other?) -- you can do this with a permutation test (check the lecture notes!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "po4mp6zRHC0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "354ee33c-463e-4afd-ba88-2deb8ac95d55"
      },
      "source": [
        "# <---INSERT YOUR CODE HERE--->\n",
        "# A function that return only mean of current and new fleet\n",
        "def only_mean_initial_data(sample,sample_size):\n",
        "  take_arr = []\n",
        "  for i in sample:\n",
        "    if math.isnan(i) == False:\n",
        "      take_arr.append(i)\n",
        "\n",
        "  size_no_nan = len(take_arr)\n",
        "  no_nan_array = np.array(take_arr)\n",
        "  original_mean = np.mean(no_nan_array)\n",
        "  return original_mean\n",
        "\n",
        "def mean_of_fleets(data_of_fleets, data_size, n_bootstraps):\n",
        "  take_arr = []\n",
        "  for i in data2:\n",
        "    if math.isnan(i) == False:\n",
        "      take_arr.append(i)\n",
        "\n",
        "  size_no_nan = len(take_arr)\n",
        "  no_nan_array = np.array(take_arr)\n",
        "  store_matrix = []\n",
        "  for i in range (n_bootstraps):\n",
        "    boot_str = np.random.choice(no_nan_array,size_no_nan)\n",
        "    store_matrix.append(boot_str)\n",
        "  store_array = np.array(store_matrix)\n",
        "  data_mean_bootstraps = np.mean(store_array, axis = 1)\n",
        "  data_mean = np.mean(data_mean_bootstraps) # data_mean taking mean from bootstr array of means\n",
        "  return data_mean \n",
        "\n",
        "def mean_and_bootstrapmean_ci(data_current_fleet,data_new_fleet, data_size, n_bootstraps, ci):\n",
        "  mean_of_current_fleet = only_mean_initial_data(data_current_fleet,len(data_current_fleet))\n",
        "  mean_of_new_fleet = only_mean_initial_data(data_new_fleet,len(data_new_fleet))\n",
        "  print('current fleets original mean = {}'.format(mean_of_current_fleet))\n",
        "  print('New fleets original mean = {}'.format(mean_of_new_fleet))\n",
        "\n",
        "  with_ci_mean_current_fleet = bootstrap_mean_ci(data_current_fleet, data_size, n_bootstraps, ci)\n",
        "  with_ci_mean_new_fleet = bootstrap_mean_ci(data_new_fleet, data_size, n_bootstraps, ci)\n",
        "  print('with {} mean of current fleet = {}'.format(ci,with_ci_mean_current_fleet))\n",
        "  print('with {} mean of new fleet = {}'.format(ci,with_ci_mean_new_fleet))\n",
        "\n",
        "\n",
        "mean_and_bootstrapmean_ci(data1, data2, len(df),3000, 95 )\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current fleets original mean = 20.14457831325301\n",
            "New fleets original mean = 30.481012658227847\n",
            "with 95 mean of current fleet = 1.579518072289158\n",
            "with 95 mean of new fleet = 2.557911392405064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = bootstrap_mean_ci(data1, len(data1), 100, 95)\n",
        "print(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbnByvrYcw3-",
        "outputId": "cf24787d-cb0c-4e1c-b8a5-a776af279ffc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.353815261044172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkxvDZG4HC0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abe1b04-fa59-4404-c41a-ec2afd97ab97"
      },
      "source": [
        "# Create your own function for a permutation test here (you will need it for the lab quiz!):\n",
        "def remove_nan(sample):\n",
        "  take_arr = []\n",
        "  for i in sample:\n",
        "    if math.isnan(i) == False:\n",
        "        take_arr.append(i)\n",
        "  size_no_nan = len(take_arr)\n",
        "  no_nan_array = np.array(take_arr)\n",
        "  return no_nan_array\n",
        "\n",
        "\n",
        "def permut_test(sample1, sample2, n_permutations):\n",
        "    \"\"\"\n",
        "    sample1: 1D array\n",
        "    sample2: 1D array (note that the size of the two arrays can be different)\n",
        "    n_permutations: number of permutations to calculate the p-value\n",
        "    \"\"\"\n",
        "    data_current = remove_nan(sample1)\n",
        "    data_new = remove_nan(sample2)\n",
        "    mean_of_current = only_mean_initial_data(sample1,len(sample1))\n",
        "    print('mean value original data',mean_of_current)\n",
        "    mean_of_new = only_mean_initial_data(sample2,len(sample2))\n",
        "    print('mean value original data',mean_of_new)\n",
        "    Tobs = mean_of_new - mean_of_current\n",
        "    print('T value of observation = ',Tobs)\n",
        "\n",
        "\n",
        "    \n",
        "    concat = np.concatenate((data_current, data_new))\n",
        "    #print(concat)\n",
        "    count = 0\n",
        "    for i in range(n_permutations):\n",
        "      perm = np.random.permutation(concat)\n",
        "      p_current = perm [:int(len(data_current))]\n",
        "      p_new = perm[int(len(data_new)):]\n",
        "      #print(len(p_current),len(p_new))\n",
        "      mean_curr_af_perm = only_mean_initial_data(p_current, len(p_current))\n",
        "      mean_new_af_perm = only_mean_initial_data(p_new, len(p_new))\n",
        "      Tperm = mean_new_af_perm-mean_curr_af_perm\n",
        "      #print('for {} th perm. Tperm is = {}'.format(i,Tperm))\n",
        "      if Tperm > Tobs :\n",
        "        count = count +1\n",
        "    \n",
        "    pvalue = count/n_permutations     \n",
        "    return pvalue\n",
        "\n",
        "test = permut_test(data1, data2, 30000)\n",
        "print('p value =', test)\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value original data 20.14457831325301\n",
            "mean value original data 30.481012658227847\n",
            "T value of observation =  10.336434344974837\n",
            "p value = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qstd = bootstrap_std_mean_ci(data1,len(data1), 10000, 95)\n",
        "print(qstd)"
      ],
      "metadata": {
        "id": "0EbDFhxer5f-",
        "outputId": "fd46b09e-464d-41c7-ddb0-9f28a30cd7dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.804845728107766\n",
            "6.954321686211641\n",
            "1.1494759581038743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The variables below represent the percentages of democratic votes in Pennsylvania and Ohio (one value for each state).\n",
        "dem_share_PA = [60.08, 40.64, 36.07, 41.21, 31.04, 43.78, 44.08, 46.85, 44.71, 46.15, 63.10, 52.20, 43.18, 40.24, 39.92, 47.87, 37.77, 40.11, 49.85, 48.61, 38.62, 54.25, 34.84, 47.75, 43.82, 55.97, 58.23, 42.97, 42.38, 36.11, 37.53, 42.65, 50.96, 47.43, 56.24, 45.60, 46.39, 35.22, 48.56, 32.97, 57.88, 36.05, 37.72, 50.36, 32.12, 41.55, 54.66, 57.81, 54.58, 32.88, 54.37, 40.45, 47.61, 60.49, 43.11, 27.32, 44.03, 33.56, 37.26, 54.64, 43.12, 25.34, 49.79, 83.56, 40.09, 60.81, 49.81]\n",
        "dem_share_OH = [56.94, 50.46, 65.99, 45.88, 42.23, 45.26, 57.01, 53.61, 59.10, 61.48, 43.43, 44.69, 54.59, 48.36, 45.89, 48.62, 43.92, 38.23, 28.79, 63.57, 38.07, 40.18, 43.05, 41.56, 42.49, 36.06, 52.76, 46.07, 39.43, 39.26, 47.47, 27.92, 38.01, 45.45, 29.07, 28.94, 51.28, 50.10, 39.84, 36.43, 35.71, 31.47, 47.01, 40.10, 48.76, 31.56, 39.86, 45.31, 35.47, 51.38, 46.33, 48.73, 41.77, 41.32, 48.46, 53.14, 34.01, 54.74, 40.67, 38.96, 46.29, 38.25, 6.80, 31.75, 46.33, 44.90, 33.57, 38.10, 39.67, 40.47, 49.44, 37.62, 36.71, 46.73, 42.20, 53.16, 52.40, 58.36, 68.02, 38.53, 34.58, 69.64, 60.50, 53.53, 36.54, 49.58, 41.97, 38.11]\n",
        "\n",
        "print(len(dem_share_PA))\n",
        "print(len(dem_share_OH))"
      ],
      "metadata": {
        "id": "FcZMvWJDyHFg",
        "outputId": "9f1ed37e-ff52-4cbf-afc2-85daa93a46f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67\n",
            "88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dem_share_PA_array = np.array(dem_share_PA)\n",
        "dem_share_OH_array = np.array(dem_share_OH)\n",
        "\n",
        "\n",
        "oh = bootstrap_mean_ci(dem_share_OH_array, len(dem_share_OH_array), 25000, 90)\n",
        "print(oh)\n",
        "pa = bootstrap_mean_ci(dem_share_PA_array, len(dem_share_PA_array), 25000, 90)\n",
        "print(pa)"
      ],
      "metadata": {
        "id": "qhRVDOQo1fPq",
        "outputId": "29fe41cf-3214-4638-d364-119db1753cef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42.58897159090908\n",
            "46.04716477272727\n",
            "3.4581931818181886\n",
            "43.53458208955224\n",
            "47.460149253731345\n",
            "3.925567164179107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "per = permut_test(dem_share_PA_array,dem_share_OH_array, 20000)\n",
        "print(per)"
      ],
      "metadata": {
        "id": "MwlnSz2S322C",
        "outputId": "890c0aa4-b239-4639-8a04-6e0d5d2b0dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean value original data 45.476417910447765\n",
            "mean value original data 44.31818181818182\n",
            "T value of observation =  -1.1582360922659447\n",
            "0.75215\n"
          ]
        }
      ]
    }
  ]
}